{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create M19 dataset\n",
    "\n",
    "This notebook creates a standardized M19 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import draftsimtools as ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial dataset\n",
    "Load data from original M19 draftsim data files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"../../data/\"\n",
    "rating_path1 = dataset_path + \"m19_rating.tsv\"\n",
    "rating_path2 = dataset_path + \"m19_land_rating.tsv\"\n",
    "drafts_path = dataset_path + \"m19_drafts.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardized Cardnames\n",
    "1. Remove commas. \n",
    "2. Use underscores.\n",
    "3. Group basic lands with different art into a single cardname."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_set = ds.create_set(rating_path1, rating_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_drafts = ds.load_drafts(drafts_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_set, raw_drafts = ds.fix_commas(cur_set, raw_drafts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = ds.create_le(cur_set[\"Name\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process draft data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Processing draft: 0.\nProcessing draft: 10000.\nProcessing draft: 20000.\nProcessing draft: 30000.\nProcessing draft: 40000.\n"
    }
   ],
   "source": [
    "drafts = ds.process_drafts(raw_drafts)\n",
    "drafts = [d for d in drafts if len(d)==45] # Remove imcomplete drafts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "drafts_train, drafts_test = train_test_split(drafts, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "drafts_tensor_test = ds.drafts_to_tensor(drafts_test, le) # Runs for ~5 minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "drafts_tensor_train = ds.drafts_to_tensor(drafts_train, le) # Runs for ~15 minutes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serialize draft data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = \"./standardized_m19/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_set.to_csv(output_folder + \"standardized_m19_rating.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_data(obj, path):\n",
    "    \"\"\"\n",
    "    Serialize an object as a python pickle file.\n",
    "    \"\"\"\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump(obj, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "serialize_data(drafts_train, output_folder + \"drafts_train.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "serialize_data(drafts_test, output_folder + \"drafts_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "serialize_data(drafts_tensor_train, output_folder + \"drafts_tensor_train.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "serialize_data(drafts_tensor_test, output_folder + \"drafts_tensor_test.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For details on how to load this data, check out the \"Load M19 Dataset\" notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}