{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bot Testing Grounds\n",
    "This notebook tests the performance of a series of bots from draftsimtools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package Importing\n",
    "\n",
    "First, we load relevant packages, including the custom draftsimtools module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports packages \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pickle\n",
    "import ast\n",
    "import numpy as np\n",
    "import datetime  \n",
    "import pandas as pd\n",
    "from operator import itemgetter\n",
    "from copy import deepcopy\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "# Workaround for variable Jupyter directories\n",
    "import sys\n",
    "sys.path.append('bots')\n",
    "\n",
    "import draftsimtools as ds\n",
    "from draftsimtools import DraftNet"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-10-f2187d822554>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-10-f2187d822554>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    Next, we set filepaths for raw drafts, the MTG Json file containing detailed info on every card, and for curated draftsim ratings of each card in the current set. Here, we will be only be working with M20 drafts.\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "### Data Loading\n",
    "\n",
    "Next, we set filepaths for raw drafts, the MTG Json file containing detailed info on every card, and for curated draftsim ratings of each card in the current set. In this notebook, we will be only be working with M19 drafts.\n",
    "\n",
    "To get access to the raw drafts and draftsim rankings, please contact [Dan Troha](https://draftsim.com/contact/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets pytorch device\n",
    "device = torch.device(\"cpu\") \n",
    "\n",
    "# Sets file paths\n",
    "jsonPath = \"../../data/AllSets.json\"\n",
    "ratingPath = \"../../data/standardized_m19/standardized_m19_rating.tsv\"\n",
    "draftPath = \"../../data/standardized_m19/drafts_test.pkl\"\n",
    "\n",
    "# Sets file paths for Bayesian bot\n",
    "pCollPath = \"bots_data/bayes_pCoDraft.csv\"\n",
    "pPackPath = \"bots_data/bayes_pChoice.csv\"\n",
    "pFullPath = \"bots_data/bayes_pFull.csv\"\n",
    "namesPath = \"bots_data/bayes_names.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read in raw drafts and Draftsim card rankings here. We also create a label encoder object to map packs to binary presence/absence vectors, which is necessary for some bots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads drafts\n",
    "drafts = None\n",
    "with open(draftPath, \"rb\") as f:\n",
    "    drafts = pickle.load(f)\n",
    "\n",
    "# Loads ratings\n",
    "m19_set = pd.read_csv(ratingPath, delimiter=\"\\t\", converters={6:ast.literal_eval})\n",
    "\n",
    "# Label-encodes card names\n",
    "le = ds.create_le(m19_set[\"Name\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "For demonstration purposes, we subset the full set of testing drafts (~22k) to just 100 drafts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsets drafts for faster runtimes - for real testing, use all drafts\n",
    "subset_drafts = drafts[:5000] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Name\nCasting Cost 1\nCasting Cost 2\nCard Type\nRarity\nRating\nColor Vector\n"
    }
   ],
   "source": [
    "for col in m19_set:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Bots\n",
    "\n",
    "We need to instantiate all of the different drafting agents.\n",
    "\n",
    "**RandomBot**: Picks cards randomly. \n",
    "\n",
    "**RaredraftBot**: Picks the rarest cards in its most-dominant color.\n",
    "\n",
    "**ClassicBot**: Picks cards with the highest draftsim score in its most-dominant colors. \n",
    "\n",
    "**BayesBot**: TODO\n",
    "\n",
    "**NNetBot**: TODO\n",
    "\n",
    "**RyanBot**: TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Name\n0            Abnormal_Endurance\n1                Act_of_Treason\n2          Aegis_of_the_Heavens\n3               Aerial_Engineer\n4                 Aether_Tunnel\n5        Aethershield_Artificer\n6            Ajani's_Last_Stand\n7             Ajani's_Pridemate\n8               Ajani's_Welcome\n9    Ajani_Adversary_of_Tyrants\n10                  Alpine_Moon\n11        Amulet_of_Safekeeping\n12            Angel_of_the_Dawn\n13                   Anticipate\n14                Apex_of_Power\n15       Arcades_the_Strategist\n16          Arcane_Encyclopedia\n17               Aven_Wind_Mage\n18             Aviation_Pioneer\n19                     Banefire\n20             Blanchwood_Armor\n21             Blood_Divination\n22                Boggart_Brute\n23                   Bogstomper\n24                  Bone_Dragon\n25                  Bone_to_Ash\n26              Brawl-Bash_Ogre\n27               Bristling_Boar\n28                       Cancel\n29           Catalyst_Elemental\n..                          ...\n235            Thorn_Lieutenant\n236            Thornhide_Wolves\n237                        Thud\n238                Timber_Gorge\n239              Titanic_Growth\n240            Tolarian_Scholar\n241            Tormenting_Voice\n242                Totally_Lost\n243            Tranquil_Expanse\n244        Transmogrifying_Wand\n245               Trumpet_Blast\n246            Trusty_Packbeast\n247           Two-Headed_Zombie\n248         Uncomfortable_Chill\n249   Vaevictis_Asmadi_the_Dire\n250              Valiant_Knight\n251             Vampire_Neonate\n252           Vampire_Sovereign\n253         Viashino_Pyromancer\n254             Vigilant_Baloth\n255                   Vine_Mare\n256         Vivien's_Invocation\n257                 Vivien_Reid\n258             Volcanic_Dragon\n259              Volley_Veteran\n260              Walking_Corpse\n261                Wall_of_Mist\n262               Wall_of_Vines\n263           Windreader_Sphinx\n264             Woodland_Stream\n\n[265 rows x 1 columns]\n"
    }
   ],
   "source": [
    "# Instantiates heuristic-based bots\n",
    "bot1 = ds.RandomBot() \n",
    "bot2 = ds.RaredraftBot(m19_set) \n",
    "bot3 = ds.ClassicBot(m19_set) \n",
    "bot4 = ds.BayesBot(le, pCollPath, pPackPath, pFullPath, namesPath)\n",
    "\n",
    "# Loads neural net from saved pytorch file\n",
    "test_net = torch.load(\"bots_data/draftnet_jan19_2020_ep23.pt\")\n",
    "test_net.eval()\n",
    "\n",
    "# Instantiates neural-network bot\n",
    "bot5 = ds.NeuralNetBot(test_net, le)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Finally, we test all of the different bots against each other by measuring their top-one accuracy on predicting human choices in the subset 100 drafts. The overall accuracy for all bots across all drafts is output, as well as csv files containing bot predictions across all drafts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Initialization time taken: 0:00:00.159424\nRandomBot time taken: 0:00:02.884970\nRaredraftBot time taken: 0:15:28.288711\nClassicBot time taken: 0:34:10.174141\nBayesBot time taken: 0:08:09.087722\nNNetBot time taken: 0:35:16.512922\nTotal time taken for 5000 drafts: 1:33:47.118500\ndraft_num       2500.500000\npick_num          23.000000\nRandomBot          0.220916\nRaredraftBot       0.306622\nClassicBot         0.444809\nBayesBot           0.432027\nNNetBot            0.481778\ndtype: float64\nWrote correct to: output_files/exact_correct.tsv\nWrote fuzzy_correct to: output_files/fuzzy_correct.tsv\nWrote rank_error to: output_files/rank_error.tsv\nWrote card_acc to: output_files/card_accuracies.tsv\n"
    }
   ],
   "source": [
    "# Tests all bots in the testing framework\n",
    "tester = ds.BotTester(subset_drafts)\n",
    "before = datetime.datetime.now()\n",
    "tester.evaluate_bots([bot1, bot2, bot3, bot4, bot5], [\"RandomBot\", \"RaredraftBot\", \"ClassicBot\", \"BayesBot\", \"NNetBot\"])\n",
    "print(\"Total time taken for 25000 drafts: \" + str(datetime.datetime.now() - before))\n",
    "tester.report_evaluations()\n",
    "tester.write_evaluations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank Example Pack\n",
    "\n",
    "To illustrate how the bots' interface works, we show how the NNetBot ranks cards in a single pack. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Anticipate': 12.157964706420898,\n",
       " 'Cancel': 11.781457901000977,\n",
       " 'Crash_Through': 10.274678230285645,\n",
       " 'Daggerback_Basilisk': 13.520963668823242,\n",
       " 'Dwindle': 14.012452125549316,\n",
       " 'Epicure_of_Blood': 12.799198150634766,\n",
       " 'Exclusion_Mage': 16.070850372314453,\n",
       " 'Hired_Blade': 11.71932315826416,\n",
       " 'Hostile_Minotaur': 11.677688598632812,\n",
       " \"Knight's_Pledge\": 13.288070678710938,\n",
       " 'Knightly_Valor': 17.361173629760742,\n",
       " 'Plains_4': 8.91723918914795,\n",
       " 'Rise_from_the_Grave': 13.873148918151855,\n",
       " 'Skeleton_Archer': 12.811566352844238}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Instantiates bot tester\n",
    "tester = ds.BotTester(subset_drafts)\n",
    "\n",
    "# Create demo collection\n",
    "demo_collection = tester.drafts[0][0]\n",
    "demo_pack = tester.drafts[0][1]\n",
    "demo_x = ds.collection_pack_to_x(demo_collection, demo_pack, le)\n",
    "\n",
    "# Return the result\n",
    "result = test_net(demo_x)\n",
    "\n",
    "# Maps numeric classes to card names and displays result\n",
    "pack_dict = {str(le.inverse_transform([i])[0]) : float(v.detach().numpy()) for i, v in enumerate(result[0,:]) if v > 0}\n",
    "display(pack_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}