{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bot Testing Grounds\n",
    "This notebook tests the performance of a series of bots from draftsimtools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package Importing\n",
    "\n",
    "First, we load relevant packages, including the custom draftsimtools module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports packages \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pickle\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from operator import itemgetter\n",
    "from copy import deepcopy\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import time\n",
    "\n",
    "# Workaround for variable Jupyter directories\n",
    "import sys\n",
    "sys.path.append('bots')\n",
    "\n",
    "import draftsimtools as ds\n",
    "from draftsimtools import DraftNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading\n",
    "\n",
    "Next, we set filepaths for raw drafts, the MTG Json file containing detailed info on every card, and for curated draftsim ratings of each card in the current set. In this notebook, we will be only be working with M19 drafts.\n",
    "\n",
    "To get access to the raw drafts and draftsim rankings, please contact [Dan Troha](https://draftsim.com/contact/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets pytorch device\n",
    "device = torch.device(\"cpu\") \n",
    "\n",
    "# Sets file paths\n",
    "jsonPath = \"../../data/AllSets.json\"\n",
    "ratingPath = \"../../data/standardized_m19/standardized_m19_rating.tsv\"\n",
    "draftPath = \"../../data/standardized_m19/drafts_test.pkl\"\n",
    "\n",
    "# Sets file paths for Bayesian bot\n",
    "pCollPath = \"bots_data/bayes_pCoDraft.csv\"\n",
    "pPackPath = \"bots_data/bayes_pChoice.csv\"\n",
    "pFullPath = \"bots_data/bayes_pFull.csv\"\n",
    "namesPath = \"bots_data/bayes_names.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read in raw drafts and Draftsim card rankings here. We also create a label encoder object to map packs to binary presence/absence vectors, which is necessary for some bots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full test dataset length: 21590\n"
     ]
    }
   ],
   "source": [
    "# Loads drafts\n",
    "drafts = None\n",
    "with open(draftPath, \"rb\") as f:\n",
    "    drafts = pickle.load(f)\n",
    "print(f'Full test dataset length: {len(drafts)}')\n",
    "    \n",
    "# Loads ratings\n",
    "m19_set = pd.read_csv(ratingPath, delimiter=\"\\t\", converters={6:ast.literal_eval})\n",
    "\n",
    "# Label-encodes card names\n",
    "le = ds.create_le(m19_set[\"Name\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For demonstration purposes, we subset the full set of testing drafts (~22k) to just 100 drafts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsets drafts for faster runtimes - for real testing, use all drafts\n",
    "subset_drafts = drafts[:1000] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Bots\n",
    "\n",
    "We need to instantiate all of the different drafting agents.\n",
    "\n",
    "**RandomBot**: Picks cards randomly. \n",
    "\n",
    "**RaredraftBot**: Picks the rarest cards in its most-dominant color.\n",
    "\n",
    "**ClassicBot**: Picks cards with the highest draftsim score in its most-dominant colors. \n",
    "\n",
    "**BayesBot**: TODO\n",
    "\n",
    "**NNetBot**: TODO\n",
    "\n",
    "**RyanBot**: TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Name\n",
      "0            Abnormal_Endurance\n",
      "1                Act_of_Treason\n",
      "2          Aegis_of_the_Heavens\n",
      "3               Aerial_Engineer\n",
      "4                 Aether_Tunnel\n",
      "5        Aethershield_Artificer\n",
      "6            Ajani's_Last_Stand\n",
      "7             Ajani's_Pridemate\n",
      "8               Ajani's_Welcome\n",
      "9    Ajani_Adversary_of_Tyrants\n",
      "10                  Alpine_Moon\n",
      "11        Amulet_of_Safekeeping\n",
      "12            Angel_of_the_Dawn\n",
      "13                   Anticipate\n",
      "14                Apex_of_Power\n",
      "15       Arcades_the_Strategist\n",
      "16          Arcane_Encyclopedia\n",
      "17               Aven_Wind_Mage\n",
      "18             Aviation_Pioneer\n",
      "19                     Banefire\n",
      "20             Blanchwood_Armor\n",
      "21             Blood_Divination\n",
      "22                Boggart_Brute\n",
      "23                   Bogstomper\n",
      "24                  Bone_Dragon\n",
      "25                  Bone_to_Ash\n",
      "26              Brawl-Bash_Ogre\n",
      "27               Bristling_Boar\n",
      "28                       Cancel\n",
      "29           Catalyst_Elemental\n",
      "..                          ...\n",
      "235            Thorn_Lieutenant\n",
      "236            Thornhide_Wolves\n",
      "237                        Thud\n",
      "238                Timber_Gorge\n",
      "239              Titanic_Growth\n",
      "240            Tolarian_Scholar\n",
      "241            Tormenting_Voice\n",
      "242                Totally_Lost\n",
      "243            Tranquil_Expanse\n",
      "244        Transmogrifying_Wand\n",
      "245               Trumpet_Blast\n",
      "246            Trusty_Packbeast\n",
      "247           Two-Headed_Zombie\n",
      "248         Uncomfortable_Chill\n",
      "249   Vaevictis_Asmadi_the_Dire\n",
      "250              Valiant_Knight\n",
      "251             Vampire_Neonate\n",
      "252           Vampire_Sovereign\n",
      "253         Viashino_Pyromancer\n",
      "254             Vigilant_Baloth\n",
      "255                   Vine_Mare\n",
      "256         Vivien's_Invocation\n",
      "257                 Vivien_Reid\n",
      "258             Volcanic_Dragon\n",
      "259              Volley_Veteran\n",
      "260              Walking_Corpse\n",
      "261                Wall_of_Mist\n",
      "262               Wall_of_Vines\n",
      "263           Windreader_Sphinx\n",
      "264             Woodland_Stream\n",
      "\n",
      "[265 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Instantiates heuristic-based bots\n",
    "bot1 = ds.RandomBot() \n",
    "bot2 = ds.RaredraftBot(m19_set) \n",
    "bot3 = ds.ClassicBot(m19_set) \n",
    "bot4 = ds.BayesBot(le, pCollPath, pPackPath, pFullPath, namesPath)\n",
    "\n",
    "# Loads neural net from saved pytorch file\n",
    "test_net = torch.load(\"bots_data/draftnet_jan19_2020_ep23.pt\")\n",
    "test_net.eval()\n",
    "\n",
    "# Instantiates neural-network bot\n",
    "bot5 = ds.NeuralNetBot(test_net, le)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we test all of the different bots against each other by measuring their top-one accuracy on predicting human choices in the subset 100 drafts. The overall accuracy for all bots across all drafts is output, as well as csv files containing bot predictions across all drafts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests all bots in the testing framework\n",
    "tic = time.time()\n",
    "tester = ds.BotTester(subset_drafts)\n",
    "tester.evaluate_bots([bot1, bot2, bot3, bot4, bot5], [\"RandomBot\", \"RaredraftBot\", \"ClassicBot\", \"BayesBot\", \"NNetBot\"])\n",
    "tester.report_evaluations()\n",
    "tester.write_evaluations()\n",
    "print(f'Finished testing {len(subset_drafts)} drafts in {round((time.time()-tic)/60):d} minutes.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank Example Pack\n",
    "\n",
    "To illustrate how the bots' interface works, we show how the NNetBot ranks cards in a single pack. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Aethershield_Artificer': 14.505582809448242,\n",
       " 'Gallant_Cavalry': 16.059925079345703,\n",
       " 'Goblin_Instigator': 16.97736167907715,\n",
       " 'Greenwood_Sentinel': 13.722554206848145,\n",
       " 'Infectious_Horror': 12.23381519317627,\n",
       " 'Loxodon_Line_Breaker': 12.887977600097656,\n",
       " 'Naturalize': 12.753551483154297,\n",
       " 'Recollect': 13.35429573059082,\n",
       " 'Root_Snare': 11.705185890197754,\n",
       " 'Rupture_Spire': 15.126949310302734,\n",
       " 'Skymarch_Bloodletter': 16.28285789489746,\n",
       " 'Skyscanner': 16.772634506225586,\n",
       " 'Swamp': 9.705110549926758,\n",
       " 'Viashino_Pyromancer': 15.538342475891113}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Instantiates bot tester\n",
    "tester = ds.BotTester(subset_drafts)\n",
    "\n",
    "# Create demo collection\n",
    "demo_collection = tester.drafts[0][0]\n",
    "demo_pack = tester.drafts[0][1]\n",
    "demo_x = ds.collection_pack_to_x(demo_collection, demo_pack, le)\n",
    "\n",
    "# Return the result\n",
    "result = test_net(demo_x)\n",
    "\n",
    "# Maps numeric classes to card names and displays result\n",
    "pack_dict = {str(le.inverse_transform([i])[0]) : float(v.detach().numpy()) for i, v in enumerate(result[0,:]) if v > 0}\n",
    "display(pack_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
