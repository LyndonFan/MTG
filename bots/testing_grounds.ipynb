{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bot Testing Grounds\n",
    "This notebook tests the performance of a series of bots from draftsimtools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package Importing\n",
    "\n",
    "First, we load relevant packages, including the custom draftsimtools module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports packages \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pickle\n",
    "import ast\n",
    "import numpy as np\n",
    "import datetime  \n",
    "import pandas as pd\n",
    "from operator import itemgetter\n",
    "from copy import deepcopy\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "# Workaround for variable Jupyter directories\n",
    "import sys\n",
    "sys.path.append('bots')\n",
    "\n",
    "import draftsimtools as ds\n",
    "from draftsimtools import DraftNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading\n",
    "\n",
    "Next, we set filepaths for raw drafts, the MTG Json file containing detailed info on every card, and for curated draftsim ratings of each card in the current set. In this notebook, we will be only be working with M19 drafts.\n",
    "\n",
    "To get access to the raw drafts and draftsim rankings, please contact [Dan Troha](https://draftsim.com/contact/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets pytorch device\n",
    "device = torch.device(\"cpu\") \n",
    "\n",
    "# Sets file paths\n",
    "# jsonPath = \"../../data/AllSets.json\"\n",
    "ratingPath = \"bots_data/nnet_train/standardized_m19_rating.tsv\"\n",
    "draftPath = \"bots_data/nnet_train/drafts_test.pkl\"\n",
    "\n",
    "# Sets file paths for Bayesian bot\n",
    "pCollPath = \"bots_data/bayes_pCoDraft.csv\"\n",
    "pPackPath = \"bots_data/bayes_pChoice.csv\"\n",
    "pFullPath = \"bots_data/bayes_pFull.csv\"\n",
    "namesPath = \"bots_data/bayes_names.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read in raw drafts and Draftsim card rankings here. We also create a label encoder object to map packs to binary presence/absence vectors, which is necessary for some bots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads drafts\n",
    "drafts = None\n",
    "with open(draftPath, \"rb\") as f:\n",
    "    drafts = pickle.load(f)\n",
    "\n",
    "# Loads ratings\n",
    "m19_set = pd.read_csv(ratingPath, delimiter=\"\\t\", converters={6:ast.literal_eval})\n",
    "\n",
    "# Label-encodes card names\n",
    "le = ds.create_le(m19_set[\"Name\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For demonstration purposes, we subset the full set of testing drafts (~22k) to just 100 drafts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21590\n"
     ]
    }
   ],
   "source": [
    "# Subsets drafts for faster runtimes - for real testing, use all drafts\n",
    "subset_drafts = drafts[:5000] \n",
    "print(len(drafts))\n",
    "if True:\n",
    "    drafts = drafts[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name\n",
      "Casting Cost 1\n",
      "Casting Cost 2\n",
      "Card Type\n",
      "Rarity\n",
      "Rating\n",
      "Color Vector\n"
     ]
    }
   ],
   "source": [
    "for col in m19_set:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Bots\n",
    "\n",
    "We need to instantiate all of the different drafting agents.\n",
    "\n",
    "**RandomBot**: Picks cards randomly. \n",
    "\n",
    "**RaredraftBot**: Picks the rarest cards in its most-dominant color.\n",
    "\n",
    "**ClassicBot**: Picks cards with the highest draftsim score in its most-dominant colors. \n",
    "\n",
    "**BayesBot**: Picks cards based on a Bayesian estimate of how often they co-occur with cards in a collection. \n",
    "\n",
    "**NNetBot**: Picks cards based on a deep neural network trained to predict picks given collections. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Name\n",
      "0      Abnormal_Endurance\n",
      "1          Act_of_Treason\n",
      "2    Aegis_of_the_Heavens\n",
      "3         Aerial_Engineer\n",
      "4           Aether_Tunnel\n",
      "..                    ...\n",
      "260        Walking_Corpse\n",
      "261          Wall_of_Mist\n",
      "262         Wall_of_Vines\n",
      "263     Windreader_Sphinx\n",
      "264       Woodland_Stream\n",
      "\n",
      "[265 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Instantiates heuristic-based bots\n",
    "bot1 = ds.RandomBot() \n",
    "bot2 = ds.RaredraftBot(m19_set) \n",
    "bot3 = ds.ClassicBot(m19_set) \n",
    "bot4 = ds.BayesBot(le, pCollPath, pPackPath, pFullPath, namesPath)\n",
    "\n",
    "# Loads neural net from saved pytorch file\n",
    "test_net = torch.load(\"bots_data/draftnet_june23_2020.pt\")\n",
    "test_net.eval()\n",
    "\n",
    "# Instantiates neural-network bot\n",
    "bot5 = ds.NeuralNetBot(test_net, le)\n",
    "\n",
    "# Loads neural net from saved pytorch file\n",
    "test_custom_net = torch.load(\"bots_data/draftnetCustom_jan31_2022_ep.pt\")\n",
    "test_custom_net.eval()\n",
    "\n",
    "# Instantiates neural-network bot\n",
    "bot6 = ds.NeuralNetBot(test_custom_net, le)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we test all of the different bots against each other by measuring their top-one accuracy on predicting human choices in the subset 100 drafts. The overall accuracy for all bots across all drafts is output, as well as csv files containing bot predictions across all drafts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization time taken: 0:00:00.007555\n",
      "RandomBot time taken: 0:00:00.061625\n",
      "RaredraftBot time taken: 0:00:10.132156\n",
      "ClassicBot time taken: 0:00:06.428515\n",
      "BayesBot time taken: 0:00:04.850858\n",
      "NNetBot time taken: 0:00:04.879359\n",
      "NNetCustomBot time taken: 0:00:04.854772\n",
      "Total time taken for 100 drafts: 0:00:32.280130\n",
      "draft_num        50.500000\n",
      "pick_num         23.000000\n",
      "RandomBot         0.226889\n",
      "RaredraftBot      0.292667\n",
      "ClassicBot        0.448889\n",
      "BayesBot          0.431778\n",
      "NNetBot           0.471556\n",
      "NNetCustomBot     0.474000\n",
      "dtype: float64\n",
      "Wrote correct to: output_files/exact_correct.tsv\n",
      "Wrote fuzzy_correct to: output_files/fuzzy_correct.tsv\n",
      "Wrote rank_error to: output_files/rank_error.tsv\n",
      "Wrote card_acc to: output_files/card_accuracies.tsv\n"
     ]
    }
   ],
   "source": [
    "# Tests all bots in the testing framework\n",
    "tester = ds.BotTester(drafts)\n",
    "before = datetime.datetime.now()\n",
    "tester.evaluate_bots([bot1, bot2, bot3, bot4, bot5, bot6], [\"RandomBot\", \"RaredraftBot\", \"ClassicBot\", \"BayesBot\", \"NNetBot\", \"NNetCustomBot\"])\n",
    "print(\"Total time taken for\", len(drafts) ,\"drafts:\",datetime.datetime.now() - before)\n",
    "tester.report_evaluations()\n",
    "tester.write_evaluations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank Example Pack\n",
    "\n",
    "To illustrate how the bots' interface works, we show how the NNetBot ranks cards in a single pack. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization time taken: 0:00:00.007351\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Boggart_Brute': 17.24131965637207,\n",
       " 'Bristling_Boar': 16.391267776489258,\n",
       " 'Disperse': 12.952291488647461,\n",
       " 'Duress': 12.309479713439941,\n",
       " 'Dwarven_Priest': 15.90805435180664,\n",
       " 'Ghirapur_Guide': 16.10085678100586,\n",
       " 'Macabre_Waltz': 12.962005615234375,\n",
       " 'Regal_Bloodlord': 15.658961296081543,\n",
       " 'Revitalize': 14.009382247924805,\n",
       " \"Rogue's_Gloves\": 15.011547088623047,\n",
       " 'Salvager_of_Secrets': 12.661223411560059,\n",
       " 'Submerged_Boneyard': 12.239510536193848,\n",
       " 'Viashino_Pyromancer': 16.456260681152344,\n",
       " 'Walking_Corpse': 12.505791664123535}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Instantiates bot tester\n",
    "tester = ds.BotTester(drafts)\n",
    "\n",
    "# Create demo collection\n",
    "demo_collection = tester.drafts[0][0]\n",
    "demo_pack = tester.drafts[0][1]\n",
    "demo_x = ds.collection_pack_to_x(demo_collection, demo_pack, le)\n",
    "\n",
    "# Return the result\n",
    "result = test_net(demo_x)\n",
    "\n",
    "# Maps numeric classes to card names and displays result\n",
    "pack_dict = {str(le.inverse_transform([i])[0]) : float(v.detach().numpy()) for i, v in enumerate(result[0,:]) if v > 0}\n",
    "display(pack_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
