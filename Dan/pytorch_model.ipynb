{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Model\n",
    "daniel.brooks@alumni.caltech.edu <br>\n",
    "Feburary 24, 2018 <br>  \n",
    "\n",
    "Next step: configure NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing imports.\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import draftsimtools as ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Torch imports.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load 1000 M19 drafts.\n",
    "m19_set = ds.create_set(\"data/m19_rating.tsv\", \"data/m19_land_rating.tsv\")\n",
    "raw_drafts = ds.load_drafts(\"data/m19_1000drafts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix commas in card names.\n",
    "m19_set, raw_drafts = ds.fix_commas(m19_set, raw_drafts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store rating information in a dictionary.\n",
    "rating_dict = ds.create_rating_dict(m19_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing draft: 0.\n"
     ]
    }
   ],
   "source": [
    "#Process the draft data.\n",
    "drafts = ds.process_drafts(raw_drafts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an M19 player. \n",
    "#b = ds.SGDBot(rating_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#Optimize rating parameters using stochastic gradient descent. (1 minute / 1000 drafts)\n",
    "#for x in range(10):\n",
    "#    b.sgd_optimization(drafts[0:25], 0.05)\n",
    "#print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write new ratings to file.\n",
    "#b.write_rating_dict(\"sgd_05_linear.tsv\")\n",
    "#b.write_error(\"error.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save draft data as a tensor.\n",
    "def create_le(cardnames):\n",
    "    \"\"\"Create label encoder for cardnames.\"\"\"\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(cardnames)\n",
    "    return le\n",
    "\n",
    "def draft_to_matrix(cur_draft, le, pack_size=15):\n",
    "    \"\"\"Transform draft from cardname list to one hot encoding.\"\"\"\n",
    "    pick_list = [np.append(le.transform(cur_draft[i]), (pack_size-len(x))*[0]) \\\n",
    "                 for i, x in enumerate(cur_draft)]\n",
    "    pick_matrix = np.int16(pick_list)\n",
    "    return pick_matrix\n",
    "\n",
    "def drafts_to_tensor(drafts, le, pack_size=15):\n",
    "    \"\"\"Create tensor of shape (num_drafts, 45, 15).\"\"\"\n",
    "    pick_tensor_list = [draft_to_matrix(d, le) for d in drafts]\n",
    "    pick_tensor = np.int16(pick_tensor_list)\n",
    "    return pick_tensor\n",
    "\n",
    "#Create drafts tensor.\n",
    "le = create_le(m19_set[\"Name\"].values)\n",
    "drafts_tensor = drafts_to_tensor(drafts, le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 45, 15)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drafts_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create torch dataset class.\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "#Drafts dataset class.\n",
    "class DraftDataset(Dataset):\n",
    "    \"\"\"Defines a draft dataset in PyTorch.\"\"\"\n",
    "    \n",
    "    def __init__(self, drafts_tensor, le):\n",
    "        \"\"\"Initialization.\"\"\"\n",
    "        self.drafts_tensor = drafts_tensor\n",
    "        self.le = le\n",
    "        self.cards_in_set = len(self.le.classes_)\n",
    "        self.pack_size = int(self.drafts_tensor.shape[1]/3)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Return a training example.\n",
    "        \"\"\"\n",
    "        #Compute number of picks in a draft.\n",
    "        draft_size = self.pack_size*3\n",
    "        \n",
    "        #Grab information on current draft.\n",
    "        pick_num = index % draft_size #0-self.pack_size*3-1\n",
    "        draft_num = int((index - pick_num)/draft_size)\n",
    "        \n",
    "        #Generate.\n",
    "        x = self.create_x(pick_num, draft_num)\n",
    "        y = self.create_y(pick_num, draft_num)\n",
    "        return x, y\n",
    "    \n",
    "    def create_x(self, pick_num, draft_num):\n",
    "        \"\"\"Generate x, input. \n",
    "        Column 1: collection vector\n",
    "                  x[i]=n -> collection has n copies of card i\n",
    "        Column 2: pack vector\n",
    "                  0 -> card not in pack\n",
    "                  1 -> card in pack\n",
    "        Efficiency optimization possible. Iterative adds to numpy array.\n",
    "        \"\"\"\n",
    "        #Initialize collection / cards in pack vector.\n",
    "        x = np.zeros([self.cards_in_set, 2], dtype = \"int16\")\n",
    "        \n",
    "        #Fill in collection vector excluding current pick.\n",
    "        for n in self.drafts_tensor[draft_num, :pick_num, 0]:\n",
    "            x[n, 0] += 1\n",
    "            \n",
    "        #Fill in pack vector.\n",
    "        cards_in_pack =  self.pack_size - pick_num%self.pack_size #Cards in current pack.\n",
    "        for n in self.drafts_tensor[draft_num, pick_num, :cards_in_pack]:\n",
    "            x[n, 1] = 1\n",
    "        \n",
    "        #Convert to Torch tensor. \n",
    "        #print(\"TEST: LEAVING OUT PACK VECTOR.\")\n",
    "        #x = torch.Tensor(x[:,0])\n",
    "        x = torch.Tensor(x)\n",
    "        return x\n",
    "    \n",
    "    def create_y(self, pick_num, draft_num, not_in_pack=0.5):\n",
    "        \"\"\"Generate y, a target pick vector.\n",
    "        Picked card is assigned a value of 1.\n",
    "        Other cards are assigned a value of 0.\n",
    "        \"\"\"\n",
    "        #Initialize target vector.\n",
    "        #y = np.array([0] * self.cards_in_set)\n",
    "        y = np.zeros([self.cards_in_set, 1], dtype = \"int16\")\n",
    "            \n",
    "        #Add picked card.\n",
    "        y[self.drafts_tensor[draft_num, pick_num, 0]] = 1\n",
    "        y = torch.Tensor(y)\n",
    "        return y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.drafts_tensor)\n",
    "    \n",
    "#Create a draft dataset.\n",
    "d = DraftDataset(drafts_tensor, le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (linear1): Linear(in_features=2, out_features=10, bias=True)\n",
      "  (linear2): Linear(in_features=10, out_features=285, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Implement NN.\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self, ss):\n",
    "        \"\"\"Placeholder NN. Currently does nothing.\n",
    "        \n",
    "        param ss: number of cards in set\n",
    "        \"\"\"\n",
    "        super(Net, self).__init__()\n",
    "        #self.fc1 = nn.Linear(ss,ss)\n",
    "        #self.fc2 = nn.Linear(ss,ss)\n",
    "        #self.sm = nn.Softmax(dim=0)\n",
    "        \n",
    "        H = 10\n",
    "        D_in = 2\n",
    "        D_out = ss\n",
    "        \n",
    "        #Placeholder. \n",
    "        #Method believes an example is x[:,i,:] -> y[:,i,:]\n",
    "        #Need an example to be x[0,:,:] -> y[0,:,:]\n",
    "        #x -> (4, 285, 2)\n",
    "        #y -> (4, 285, 1)\n",
    "        self.linear1 = torch.nn.Linear(D_in, H)\n",
    "        self.linear2 = torch.nn.Linear(H, D_out)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #x dimensions are (batch, cards_set, 2)\n",
    "        #x0 = x[:, 0] #Collection\n",
    "        #x1 = x[:, :, 1] #Cards in pack\n",
    "        \n",
    "        #print(x.shape)\n",
    "        \n",
    "        #xt = np.transpose(x)\n",
    "        #x0 = xt[0,:]\n",
    "        \n",
    "        #Desired forward prop function.\n",
    "        #out = self.fc1(x0)\n",
    "        #out = F.relu(self.fc1(x))\n",
    "        #out = F.relu(self.fc2(out))\n",
    "        #out = out * x1 #Constrain cards based on what is in pack.\n",
    "        #out = self.sm(out)\n",
    "        #out = x\n",
    "        h_relu = self.linear1(x)\n",
    "        y_pred = self.linear2(h_relu)\n",
    "        return y_pred\n",
    "\n",
    "#Create NN.\n",
    "net = Net(len(m19_set))\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# Define training parameters. #\n",
    "###############################\n",
    "\n",
    "#Define training set. Batchsize must be 1.\n",
    "trainset = d\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True)\n",
    "\n",
    "#Loss function.\n",
    "criterion = nn.MSELoss()\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#Define optimizer. \n",
    "optimizer = optim.SGD(net.parameters(), lr=0.5, momentum=0.9)\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Average Loss: 0.007219\n",
      "Epoch 2, Average Loss: 0.003469\n",
      "Epoch 3, Average Loss: 0.003458\n",
      "Epoch 4, Average Loss: 0.003450\n",
      "Epoch 5, Average Loss: 0.003441\n",
      "Epoch 6, Average Loss: 0.003430\n",
      "Epoch 7, Average Loss: 0.003418\n",
      "Epoch 8, Average Loss: 0.003403\n",
      "Epoch 9, Average Loss: 0.003387\n",
      "Epoch 10, Average Loss: 0.003369\n",
      "Epoch 11, Average Loss: 0.003349\n",
      "Epoch 12, Average Loss: 0.003328\n",
      "Epoch 13, Average Loss: 0.003306\n",
      "Epoch 14, Average Loss: 0.003284\n",
      "Epoch 15, Average Loss: 0.003261\n",
      "Epoch 16, Average Loss: 0.003239\n",
      "Epoch 17, Average Loss: 0.003218\n",
      "Epoch 18, Average Loss: 0.003198\n",
      "Epoch 19, Average Loss: 0.003179\n",
      "Epoch 20, Average Loss: 0.003163\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Train network.\n",
    "\n",
    "#Set up pulled from pytorch tutorial.\n",
    "#https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-download-beginner-blitz-cifar10-tutorial-py\n",
    "\n",
    "NUM_EPOCH = 20\n",
    "num_draft = len(trainloader)\n",
    "\n",
    "for epoch in range(NUM_EPOCH):\n",
    "    \n",
    "    #Loop over x,y for each dataset.\n",
    "    running_loss = 0\n",
    "    for i, data in enumerate(trainloader):\n",
    "        \n",
    "        #Get the inputs. Keeps batch size.\n",
    "        inputs, labels = data\n",
    "        #print(inputs.shape, labels.shape)\n",
    "        #inputs = data[0][0,:,:]\n",
    "        #labels = data[1][0,:,:]\n",
    "        #print(inputs.shape, labels.shape)\n",
    "                \n",
    "        #Zero parameter gradients between batches.\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #Perform training.\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #Print loss data.\n",
    "        running_loss += loss.item()\n",
    "        if i % num_draft == num_draft-1:\n",
    "            print('Epoch %d, Average Loss: %.6f' % (epoch+1, running_loss/num_draft))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "print(\"Finished Training\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
