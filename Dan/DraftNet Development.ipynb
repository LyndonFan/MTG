{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DraftNet Development\n",
    "daniel.brooks@alumni.caltech.edu <br>\n",
    "July 1, 2019 <br>  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing imports.\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from tqdm import tqdm\n",
    "\n",
    "import draftsimtools as ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Torch imports.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.dataset import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toggle GPU/CPU mode.\n",
    "device = torch.device(\"cpu\") # Use CPU device for saving model.\n",
    "# device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell now included in draftsimtools (without GPU support).\n",
    "def create_le(cardnames):\n",
    "    \"\"\"Create label encoder for cardnames.\"\"\"\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(cardnames)\n",
    "    return le\n",
    "\n",
    "def draft_to_matrix(cur_draft, le, pack_size=15):\n",
    "    \"\"\"Transform draft from cardname list to one hot encoding.\"\"\"\n",
    "    pick_list = [np.append(le.transform(cur_draft[i]), (pack_size-len(x))*[0]) \\\n",
    "                 for i, x in enumerate(cur_draft)]\n",
    "    pick_matrix = np.int16(pick_list, device=device)\n",
    "    return pick_matrix\n",
    "\n",
    "def drafts_to_tensor(drafts, le, pack_size=15):\n",
    "    \"\"\"Create tensor of shape (num_drafts, 45, 15).\"\"\"\n",
    "    pick_tensor_list = [draft_to_matrix(d, le) for d in drafts]\n",
    "    pick_tensor = np.int16(pick_tensor_list, device=device)\n",
    "    return pick_tensor\n",
    "\n",
    "#Drafts dataset class.\n",
    "class DraftDataset(Dataset):\n",
    "    \"\"\"Defines a draft dataset in PyTorch.\"\"\"\n",
    "    \n",
    "    def __init__(self, drafts_tensor, le):\n",
    "        \"\"\"Initialization.\n",
    "        \"\"\"\n",
    "        self.drafts_tensor = drafts_tensor\n",
    "        self.le = le\n",
    "        self.cards_in_set = len(self.le.classes_)\n",
    "        self.pack_size = int(self.drafts_tensor.shape[1]/3)\n",
    "        self.draft_size = self.pack_size*3\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Return a training example.\n",
    "        \"\"\"\n",
    "        #Grab information on current draft.\n",
    "        pick_num = index % self.draft_size #0-self.pack_size*3-1\n",
    "        draft_num = int((index - pick_num)/self.draft_size)\n",
    "        \n",
    "        #Generate.\n",
    "        x = self.create_new_x(pick_num, draft_num)\n",
    "        y = self.create_new_y(pick_num, draft_num)\n",
    "        return x, y\n",
    "    \n",
    "    def create_new_x(self, pick_num, draft_num):\n",
    "        \"\"\"Generate x, input, as a row vector.\n",
    "        0:n     : collection vector\n",
    "                  x[i]=n -> collection has n copies of card i\n",
    "        n:2n    : pack vector\n",
    "                  0 -> card not in pack\n",
    "                  1 -> card in pack\n",
    "        Efficiency optimization possible. Iterative adds to numpy array.\n",
    "        \"\"\"\n",
    "        #Initialize collection / cards in pack vector.\n",
    "        x = np.zeros([self.cards_in_set * 2], dtype = \"int16\")\n",
    "        \n",
    "        #Fill in collection vector excluding current pick (first half).\n",
    "        for n in self.drafts_tensor[draft_num, :pick_num, 0]:\n",
    "            x[n] += 1\n",
    "            \n",
    "        #Fill in pack vector.\n",
    "        cards_in_pack =  self.pack_size - pick_num%self.pack_size #Cards in current pack.\n",
    "        for n in self.drafts_tensor[draft_num, pick_num, :cards_in_pack]:\n",
    "            x[n + self.cards_in_set] = 1\n",
    "            \n",
    "        #Convert to Torch tensor.\n",
    "        x = torch.Tensor(x)\n",
    "        return x\n",
    "    \n",
    "    def create_new_y(self, pick_num, draft_num, not_in_pack=0.5):\n",
    "        \"\"\"Generate y, a target pick row vector.\n",
    "        Picked card is assigned a value of 1.\n",
    "        Other cards are assigned a value of 0.\n",
    "        \"\"\"\n",
    "        #Initialize target vector.\n",
    "        #y = np.array([0] * self.cards_in_set)\n",
    "        y = np.zeros([self.cards_in_set], dtype = \"int16\")\n",
    "            \n",
    "        #Add picked card.\n",
    "        y[self.drafts_tensor[draft_num, pick_num, 0]] = 1\n",
    "        #y = torch.Tensor(y, dtype=torch.int64) # Needed as target.\n",
    "        y = torch.tensor(y, dtype=torch.int64, device=device) # Needed as target.\n",
    "        return y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.drafts_tensor) * self.draft_size\n",
    "\n",
    "def load_dataset(rating_path1, rating_path2, drafts_path):\n",
    "    \"\"\"Create drafts tensor from drafts and set files.\"\"\"\n",
    "    # Load the set. inputs\n",
    "    cur_set = ds.create_set(rating_path1, rating_path2)\n",
    "    raw_drafts = ds.load_drafts(drafts_path)\n",
    "    \n",
    "    # Fix commas. \n",
    "    cur_set, raw_drafts = ds.fix_commas(cur_set, raw_drafts)\n",
    "    \n",
    "    # Process drafts. \n",
    "    drafts = ds.process_drafts(raw_drafts)\n",
    "    \n",
    "    # Drop empty elements at end, if present. \n",
    "    while len(drafts[-1]) == 0:\n",
    "        drafts = drafts[:-1]\n",
    "    \n",
    "    # Create a label encoder.\n",
    "    le = create_le(cur_set[\"Name\"].values)\n",
    "    \n",
    "    # Create drafts tensor. \n",
    "    drafts_tensor = drafts_to_tensor(drafts, le)\n",
    "    \n",
    "    # Create a dataset.\n",
    "    cur_dataset = DraftDataset(drafts_tensor, le)\n",
    "    \n",
    "    # Get the tensor\n",
    "    return cur_dataset, drafts_tensor, cur_set, le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing draft: 0.\n",
      "Processing draft: 10000.\n",
      "Processing draft: 0.\n"
     ]
    }
   ],
   "source": [
    "# Define rating file paths. \n",
    "rating_path1 = \"data/m19_rating.tsv\"\n",
    "rating_path2 = \"data/m19_land_rating.tsv\"\n",
    "\n",
    "# Load data. \n",
    "train_data, train_tensor, m19_set, le = ds.load_dataset(rating_path1, rating_path2, \"data/subset20000/train.csv\")\n",
    "val_data, val_tensor, m19_set, le = ds.load_dataset(rating_path1, rating_path2, \"data/subset20000/val.csv\")\n",
    "#test_data, test_tensor, m19_set, le = load_dataset(rating_path1, rating_path2, \"data/subset20000/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Casting Cost 1</th>\n",
       "      <th>Casting Cost 2</th>\n",
       "      <th>Card Type</th>\n",
       "      <th>Rarity</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Color Vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abnormal_Endurance</td>\n",
       "      <td>1B</td>\n",
       "      <td>none</td>\n",
       "      <td>Instant</td>\n",
       "      <td>C</td>\n",
       "      <td>2.2</td>\n",
       "      <td>[0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Act_of_Treason</td>\n",
       "      <td>2R</td>\n",
       "      <td>none</td>\n",
       "      <td>Spell</td>\n",
       "      <td>C</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[0, 0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aegis_of_the_Heavens</td>\n",
       "      <td>1W</td>\n",
       "      <td>none</td>\n",
       "      <td>Instant</td>\n",
       "      <td>U</td>\n",
       "      <td>1.9</td>\n",
       "      <td>[1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aerial_Engineer</td>\n",
       "      <td>2UW</td>\n",
       "      <td>none</td>\n",
       "      <td>Creature</td>\n",
       "      <td>U</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[1, 1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aether_Tunnel</td>\n",
       "      <td>1U</td>\n",
       "      <td>none</td>\n",
       "      <td>Spell</td>\n",
       "      <td>U</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Name Casting Cost 1 Casting Cost 2 Card Type Rarity  \\\n",
       "0    Abnormal_Endurance             1B           none   Instant      C   \n",
       "1        Act_of_Treason             2R           none     Spell      C   \n",
       "2  Aegis_of_the_Heavens             1W           none   Instant      U   \n",
       "3       Aerial_Engineer            2UW           none  Creature      U   \n",
       "4         Aether_Tunnel             1U           none     Spell      U   \n",
       "\n",
       "   Rating     Color Vector  \n",
       "0     2.2  [0, 0, 1, 0, 0]  \n",
       "1     2.0  [0, 0, 0, 1, 0]  \n",
       "2     1.9  [1, 0, 0, 0, 0]  \n",
       "3     3.0  [1, 1, 0, 0, 0]  \n",
       "4     2.0  [0, 1, 0, 0, 0]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m19_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_set_vector(casting_cost, card_type, rarity, color_vector):\n",
    "    \"\"\"\n",
    "    Returns a one hot encoded card property vector. \n",
    "    \n",
    "    There are 21 binary features:\n",
    "    \n",
    "    0. cmc=0\n",
    "    1. cmc=1\n",
    "    2. cmc=2\n",
    "    3. cmc=3\n",
    "    4. cmc=4\n",
    "    5. cmc=5\n",
    "    6. cmc=6\n",
    "    7. cmc>=7\n",
    "    8. creature?\n",
    "    9. common?\n",
    "    10. uncommon?\n",
    "    11. rare?\n",
    "    12. mythic?\n",
    "    13. colorless?\n",
    "    14. monocolored?\n",
    "    15. multicolored?\n",
    "    16. color1?\n",
    "    17. color2?\n",
    "    18. color3?\n",
    "    19. color4?\n",
    "    20. color5?\n",
    "    \n",
    "    :param casting_cost: integer casting cost of card\n",
    "    :param card_type: \"Creature\" or other\n",
    "    :param rarity\": \"C\", \"U\", \"R\", or \"M\"\n",
    "    \"param color_vector\": vector corresponding to colors of card, example: [1,0,0,0,1]\n",
    "    \n",
    "    \"\"\"\n",
    "    # Initialize set vector.\n",
    "    v = [0] * 21\n",
    "    \n",
    "    # Encode cmc. \n",
    "    if casting_cost == 0:\n",
    "        v[0] = 1\n",
    "    elif casting_cost == 1:\n",
    "        v[1] = 1\n",
    "    elif casting_cost == 2:\n",
    "        v[2] = 1\n",
    "    elif casting_cost == 3:\n",
    "        v[3] = 1\n",
    "    elif casting_cost == 4:\n",
    "        v[4] = 1\n",
    "    elif casting_cost == 5:\n",
    "        v[5] = 1\n",
    "    elif casting_cost == 6:\n",
    "        v[6] = 1\n",
    "    elif casting_cost >= 7:\n",
    "        v[7] = 1\n",
    "    else:\n",
    "        print(\"WARNING: Undefined casting cost.\")\n",
    "    \n",
    "    # Encode type.\n",
    "    if card_type == \"Creature\":\n",
    "        v[8] = 1\n",
    "        \n",
    "    # Encode rarity.\n",
    "    if rarity == \"C\":\n",
    "        v[9] = 1\n",
    "    elif rarity == \"U\":\n",
    "        v[10] = 1\n",
    "    elif rarity == \"R\":\n",
    "        v[11] = 1\n",
    "    elif rarity == \"M\":\n",
    "        v[12] = 1\n",
    "    \n",
    "    # Process number of colors.\n",
    "    num_colors = len([c for c in color_vector if c > 0])\n",
    "    if num_colors == 0:\n",
    "        v[13] = 1\n",
    "    elif num_colors == 1:\n",
    "        v[14] = 1\n",
    "    elif num_colors >= 2:\n",
    "        v[15] = 1\n",
    "    \n",
    "    # Process card color. \n",
    "    if color_vector[0] > 0:\n",
    "        v[16] = 1\n",
    "    if color_vector[1] > 0:\n",
    "        v[17] = 1\n",
    "    if color_vector[2] > 0:\n",
    "        v[18] = 1\n",
    "    if color_vector[3] > 0:\n",
    "        v[19] = 1\n",
    "    if color_vector[4] > 0:\n",
    "        v[20] = 1\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmc_from_string(cmc_string):\n",
    "    \"\"\"\n",
    "    Return an integer converted mana cost from cmc_string. \n",
    "    \n",
    "    Each character adds 1 to cmc. \n",
    "    \n",
    "    :param cmc_string: String or integer representation of cmc. Example: \"1UBR\".\n",
    "    :returns: Integer cmc. Example: 4.\n",
    "    \"\"\"\n",
    "    # If int, we are done. \n",
    "    if type(cmc_string) is int:\n",
    "        return cmc_string\n",
    "    \n",
    "    # Convert string to integer cmc.\n",
    "    cmc = 0\n",
    "    digit_string = \"\"\n",
    "    letters = set(\"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\")\n",
    "    digits = set(\"1234567890\")\n",
    "        \n",
    "    for c in cmc_string:        \n",
    "        if c in letters:\n",
    "            cmc += 1\n",
    "        else:\n",
    "            digit_string += c\n",
    "    if len(digit_string) > 0:\n",
    "        cmc += int(digit_string)\n",
    "    return cmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_set_tensor(magic_set):\n",
    "    \"\"\"\n",
    "    Returns a set tensor which represents the properties of cards in the set.\n",
    "    \n",
    "    There are M features and N cards in the set and the tensor is of size M x N.\n",
    "    \n",
    "    The features are documented in the create_set_vector() function. \n",
    "    \"\"\"\n",
    "    set_list = []\n",
    "    \n",
    "    # Requires these names to be present in the set file.\n",
    "    reduced_set = magic_set[[\"Name\", \"Casting Cost 1\", \"Card Type\", \"Rarity\", \"Color Vector\"]]\n",
    "    for index, row in reduced_set.iterrows():\n",
    "        card_vector = create_set_vector(cmc_from_string(row[1]), row[2], row[3], row[4])\n",
    "        set_list.append(card_vector)\n",
    "        \n",
    "    # set_list is currently N x M list of lists. \n",
    "    set_flipped = torch.Tensor(set_list)\n",
    "    set_tensor = torch.transpose(set_flipped, 0, 1)\n",
    "    return set_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([21, 285])\n"
     ]
    }
   ],
   "source": [
    "# Set tensor.\n",
    "st = create_set_tensor(m19_set)\n",
    "if device.type != \"cpu\":\n",
    "    st = st.cuda()\n",
    "print(st.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implement NN.\n",
    "class DraftNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, set_tensor):\n",
    "        \"\"\"Placeholder NN. Currently does nothing.\n",
    "        \n",
    "        param ss: number of cards in set\n",
    "        param set_tensor: Mxss set tensor describing the set\n",
    "        \"\"\"\n",
    "        super(DraftNet, self).__init__()\n",
    "        \n",
    "        # Load set tensor.\n",
    "        self.set_tensor = set_tensor\n",
    "        self.set_tensor_tranpose = torch.transpose(set_tensor, 0, 1)\n",
    "        self.M, self.ss = self.set_tensor.shape\n",
    "        self.half_ss = self.ss / 2\n",
    "        \n",
    "        # Specify layer sizes. \n",
    "        size_in = self.ss + self.M\n",
    "        #size_in = self.ss\n",
    "        size1 = self.ss\n",
    "        size2 = self.ss\n",
    "        size3 = self.ss\n",
    "        size4 = self.ss\n",
    "        size5 = self.ss\n",
    "        size6 = self.ss\n",
    "        size7 = self.ss\n",
    "        size8 = self.ss\n",
    "        \n",
    "        self.ns = 0.01\n",
    "        \n",
    "        self.bn = nn.BatchNorm1d(self.ss + self.M)\n",
    "        \n",
    "        self.linear1 = torch.nn.Linear(size_in, size1)\n",
    "        self.bn1 = nn.BatchNorm1d(size1)\n",
    "        self.relu1 = torch.nn.LeakyReLU(negative_slope = self.ns)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.linear2 = torch.nn.Linear(size1, size2)\n",
    "        self.bn2 = nn.BatchNorm1d(size2)\n",
    "        self.relu2 = torch.nn.LeakyReLU(negative_slope = self.ns)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.linear3 = torch.nn.Linear(size2, size3)\n",
    "        self.bn3 = nn.BatchNorm1d(size3)\n",
    "        self.relu3 = torch.nn.LeakyReLU(negative_slope = self.ns)\n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.linear4 = torch.nn.Linear(size3, size4)\n",
    "        self.relu4 = torch.nn.LeakyReLU(negative_slope = self.ns)\n",
    "        self.dropout4 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.linear5 = torch.nn.Linear(size3, size5)\n",
    "        self.relu5 = torch.nn.LeakyReLU(negative_slope = self.ns)\n",
    "        self.dropout5 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.linear6 = torch.nn.Linear(size3, size6)\n",
    "        self.relu6 = torch.nn.LeakyReLU(negative_slope = self.ns)\n",
    "        self.dropout6 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.linear7 = torch.nn.Linear(size3, size7)\n",
    "        self.relu7 = torch.nn.LeakyReLU(negative_slope = self.ns)\n",
    "        self.dropout7 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.linear8 = torch.nn.Linear(size3, size8)\n",
    "        self.relu8 = torch.nn.LeakyReLU(negative_slope = self.ns)\n",
    "        \n",
    "        \n",
    "        #self.sm = torch.nn.Softmax()\n",
    "                \n",
    "    def forward(self, x):\n",
    "        \n",
    "        collection = x[:, :self.ss]\n",
    "        \n",
    "        #collection = self.bn(collection)\n",
    "        \n",
    "        pack = x[:, self.ss:]\n",
    "        \n",
    "        # Get features from set tensor. \n",
    "        features = torch.mm(collection, self.set_tensor_tranpose)\n",
    "        collection_and_features = torch.cat((collection, features), 1)\n",
    "        \n",
    "        collection_and_features = self.bn(collection_and_features)\n",
    "        \n",
    "        #y = self.linear1(collection_and_features)\n",
    "        y = self.linear1(collection_and_features)\n",
    "        y = self.bn1(y)\n",
    "        y = self.relu1(y)\n",
    "        y = self.dropout1(y)\n",
    "        \n",
    "        y = self.linear2(y)\n",
    "        y = self.bn2(y)\n",
    "        y = self.relu2(y)\n",
    "        y = self.dropout2(y)\n",
    "        \n",
    "        y = self.linear3(y)\n",
    "        y = self.bn3(y)\n",
    "        y = self.relu3(y)\n",
    "        y = self.dropout3(y)\n",
    "\n",
    "        y = self.linear4(y)\n",
    "        #y = self.relu4(y)\n",
    "        #y = self.dropout4(y)\n",
    "        \n",
    "        #y = self.linear5(y)\n",
    "        #y = self.relu5(y)\n",
    "        #y = self.dropout5(y)\n",
    "        \n",
    "        #y = self.linear6(y)\n",
    "        #y = self.relu6(y)\n",
    "        #y = self.dropout6(y)\n",
    "        \n",
    "        #y = self.linear7(y)\n",
    "        #y = self.relu7(y)\n",
    "        #y = self.dropout7(y)\n",
    "        \n",
    "        #y = self.linear8(y)\n",
    "        #y = self.relu8(y)\n",
    "        \n",
    "        y = y * pack # Enforce cards in pack only.\n",
    "        \n",
    "        return y\n",
    "\n",
    "#Create NN.\n",
    "net = DraftNet(st)\n",
    "\n",
    "if device.type != \"cpu\":\n",
    "    net = net.cuda()\n",
    "\n",
    "#print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net(net, dataloader, num_epoch, optimizer):\n",
    "    \"\"\"Train the network.\"\"\"\n",
    "    net.train()    \n",
    "    my_count = 0\n",
    "    for epoch in range(num_epoch):\n",
    "        \n",
    "        #Loop over x,y for each dataset.\n",
    "        running_loss = 0\n",
    "        for i, data in enumerate(dataloader):\n",
    "        \n",
    "            my_count+=1\n",
    "            if my_count % 10000 == 0:\n",
    "                print(my_count)\n",
    "        \n",
    "            #Get the inputs. Keeps batch size.\n",
    "            x, y = data\n",
    "            \n",
    "            # cuda() is needed for GPU mode. Not sure why.\n",
    "            if device.type != \"cpu\":\n",
    "                x = x.cuda()\n",
    "                y = y.cuda() # One-hot encoded. \n",
    "            \n",
    "            # Zero parameter gradients between batches.\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            #Perform training.\n",
    "            y_pred = net(x)\n",
    "            y_integer = torch.argmax(y, 1) # Class indices.\n",
    "            \n",
    "            # Use cross entropy loss. \n",
    "            loss = torch.nn.CrossEntropyLoss()\n",
    "            output = loss(y_pred, y_integer)\n",
    "            output.backward()\n",
    "            optimizer.step()\n",
    "                        \n",
    "            #Print loss data.\n",
    "            running_loss += output.item()\n",
    "            step = 1\n",
    "            if i % len(dataloader) == len(dataloader)-1 and (epoch + 1) % step == 0:\n",
    "                print('Train Cross-Entropy Loss: %.6f' % (running_loss/len(dataloader)))\n",
    "                running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataloaders. \n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=100, shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(val_data, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_net(net, dataloader):\n",
    "    \"\"\"Compute accuracy on validation set.\"\"\"\n",
    "    net.eval()\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(dataloader):\n",
    "        \n",
    "            #Get the inputs. Keeps batch size.\n",
    "            x, y = data\n",
    "            \n",
    "            # cuda() is needed for GPU mode. Not sure why.\n",
    "            if device.type != \"cpu\":\n",
    "                x = x.cuda()\n",
    "                y = y.cuda()\n",
    "            y_integer = torch.argmax(y, 1) # Class indices.\n",
    "            \n",
    "            # Compute val loss.\n",
    "            y_pred = net(x)\n",
    "            y_pred_integer = torch.argmax(y_pred, 1)\n",
    "            \n",
    "            # Compute accuracy. \n",
    "            correct += int(sum(y_pred_integer == y_integer))\n",
    "            total += len(y_integer)\n",
    "            \n",
    "    accuracy = correct / total\n",
    "\n",
    "    print(\"Validation accuracy:\", accuracy, \" Total picks:\", int(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train Cross-Entropy Loss: 1.556999\n",
      "Validation accuracy: 0.6094888888888889  Total picks: 225000\n",
      "Epoch: 2\n",
      "Train Cross-Entropy Loss: 1.128761\n",
      "Validation accuracy: 0.6149911111111112  Total picks: 225000\n",
      "Epoch: 3\n",
      "Train Cross-Entropy Loss: 1.092715\n",
      "Validation accuracy: 0.6203155555555555  Total picks: 225000\n",
      "Epoch: 4\n",
      "Train Cross-Entropy Loss: 1.073860\n",
      "Validation accuracy: 0.6242266666666667  Total picks: 225000\n",
      "Epoch: 5\n",
      "Train Cross-Entropy Loss: 1.057837\n",
      "Validation accuracy: 0.6267511111111111  Total picks: 225000\n",
      "Epoch: 6\n",
      "Train Cross-Entropy Loss: 1.047161\n",
      "Validation accuracy: 0.6287333333333334  Total picks: 225000\n",
      "Epoch: 7\n",
      "Train Cross-Entropy Loss: 1.038243\n",
      "Validation accuracy: 0.62904  Total picks: 225000\n",
      "Epoch: 8\n",
      "Train Cross-Entropy Loss: 1.031546\n",
      "Validation accuracy: 0.6302444444444445  Total picks: 225000\n",
      "Epoch: 9\n",
      "Train Cross-Entropy Loss: 1.025911\n",
      "Validation accuracy: 0.6316533333333333  Total picks: 225000\n",
      "Epoch: 10\n",
      "Train Cross-Entropy Loss: 1.021085\n",
      "Validation accuracy: 0.6328622222222222  Total picks: 225000\n",
      "Epoch: 11\n",
      "Train Cross-Entropy Loss: 1.018222\n",
      "Validation accuracy: 0.6335377777777778  Total picks: 225000\n",
      "Epoch: 12\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-b8db3157d596>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# Train1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mtrain_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-1bcb77106979>\u001b[0m in \u001b[0;36mtrain_net\u001b[0;34m(net, dataloader, num_epoch, optimizer)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_integer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the network over several epochs - no momentu, from scratch.\n",
    "run = 0\n",
    "\n",
    "# Now leave optimizer out here. \n",
    "#optimizer = optim.Adam(net.parameters(), lr=0.05, betas=(0.9, 0.999))\n",
    "#optimizer = optim.ASGD(net.parameters())\n",
    "#optimizer = torch.optim.SGD(net.parameters(), lr=0.1, momentum=0.9)\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.1, momentum=0.0)\n",
    "#optimizer = torch.optim.RMSprop(net.parameters(), lr=0.1, momentum=0.0)\n",
    "# scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = 0.33) # Used for exp 47.\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = 0.85)\n",
    "\n",
    "ep = 0\n",
    "\n",
    "for run in range(999999):\n",
    "    \n",
    "    ep += 1\n",
    "    print(\"Epoch:\", ep)\n",
    "    \n",
    "    # Train1.\n",
    "    train_net(net, trainloader, 1, optimizer)\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Validation. \n",
    "    val_net(net, valloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload 0.636\n",
    "# net = torch.load(\"draftnet_aug_22_2019.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train the network over several epochs - no momentu, from scratch.\n",
    "run = 360\n",
    "\n",
    "# Now leave optimizer out here. \n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "#optimizer = optim.ASGD(net.parameters())\n",
    "#optimizer = torch.optim.SGD(net.parameters(), lr=0.1, momentum=0.9)\n",
    "\n",
    "#optimizer = torch.optim.SGD(net.parameters(), lr=0.1, momentum=0.0)\n",
    "#optimizer = torch.optim.RMSprop(net.parameters(), lr=0.01, momentum=0.0)\n",
    "# scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = 0.33) # Used for exp 47.\n",
    "#scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = 0.97)\n",
    "\n",
    "ep = 0\n",
    "\n",
    "for run in range(999999):\n",
    "    \n",
    "    ep += 1\n",
    "    print(\"Epoch:\", ep)\n",
    "    \n",
    "    # Train1.\n",
    "    train_net(net, trainloader, 1, optimizer)\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Validation. \n",
    "    val_net(net, valloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(net, \"draftnet_aug_23_2019.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train the network over several epochs - no momentu, from scratch.\n",
    "run = 53\n",
    "\n",
    "# Now leave optimizer out here. \n",
    "#optimizer = optim.Adam(net.parameters(), lr=0.0001, betas=(0.9, 0.999)) #Good\n",
    "#optimizer = optim.ASGD(net.parameters())\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.00001, momentum=0.0)\n",
    "\n",
    "#optimizer = torch.optim.SGD(net.parameters(), lr=0.1, momentum=0.0)\n",
    "#optimizer = torch.optim.RMSprop(net.parameters(), lr=0.01, momentum=0.0)\n",
    "# scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = 0.33) # Used for exp 47.\n",
    "#scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = 0.985)\n",
    "\n",
    "ep = 685\n",
    "\n",
    "for run in range(999999):\n",
    "    \n",
    "    ep += 1\n",
    "    print(\"Epoch:\", ep)\n",
    "    \n",
    "    # Train1.\n",
    "    train_net(net, trainloader, 1, optimizer)\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Validation. \n",
    "    val_net(net, valloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.SGD(net.parameters(), lr=0.00001, momentum=0.0)\n",
    "# # scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = 0.33) # Used for exp 47.\n",
    "# scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = 0.8)\n",
    "\n",
    "# ep = 0\n",
    "\n",
    "# for run in range(999999):\n",
    "    \n",
    "#     ep += 1\n",
    "#     print(\"Epoch:\", ep)\n",
    "    \n",
    "#     # Train1.\n",
    "#     train_net(net, trainloader, 1, optimizer)\n",
    "#     scheduler.step()\n",
    "    \n",
    "#     # Validation. \n",
    "#     val_net(net, valloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(net, \"draftnet_oct_17_2019_633_cpu.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.0001 * 0.985 ** 685"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
