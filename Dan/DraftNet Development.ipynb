{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DraftNet Development\n",
    "daniel.brooks@alumni.caltech.edu <br>\n",
    "July 1, 2019 <br>  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing imports.\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from tqdm import tqdm\n",
    "\n",
    "import draftsimtools as ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Torch imports.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.dataset import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toggle GPU/CPU mode.\n",
    "# device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_le(cardnames):\n",
    "    \"\"\"Create label encoder for cardnames.\"\"\"\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(cardnames)\n",
    "    return le\n",
    "\n",
    "def draft_to_matrix(cur_draft, le, pack_size=15):\n",
    "    \"\"\"Transform draft from cardname list to one hot encoding.\"\"\"\n",
    "    pick_list = [np.append(le.transform(cur_draft[i]), (pack_size-len(x))*[0]) \\\n",
    "                 for i, x in enumerate(cur_draft)]\n",
    "    pick_matrix = np.int16(pick_list, device=device)\n",
    "    return pick_matrix\n",
    "\n",
    "def drafts_to_tensor(drafts, le, pack_size=15):\n",
    "    \"\"\"Create tensor of shape (num_drafts, 45, 15).\"\"\"\n",
    "    pick_tensor_list = [draft_to_matrix(d, le) for d in drafts]\n",
    "    pick_tensor = np.int16(pick_tensor_list, device=device)\n",
    "    return pick_tensor\n",
    "\n",
    "#Drafts dataset class.\n",
    "class DraftDataset(Dataset):\n",
    "    \"\"\"Defines a draft dataset in PyTorch.\"\"\"\n",
    "    \n",
    "    def __init__(self, drafts_tensor, le):\n",
    "        \"\"\"Initialization.\n",
    "        \"\"\"\n",
    "        self.drafts_tensor = drafts_tensor\n",
    "        self.le = le\n",
    "        self.cards_in_set = len(self.le.classes_)\n",
    "        self.pack_size = int(self.drafts_tensor.shape[1]/3)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Return a training example.\n",
    "        \"\"\"\n",
    "        #Compute number of picks in a draft.\n",
    "        draft_size = self.pack_size*3\n",
    "        \n",
    "        #Grab information on current draft.\n",
    "        pick_num = index % draft_size #0-self.pack_size*3-1\n",
    "        draft_num = int((index - pick_num)/draft_size)\n",
    "        \n",
    "        #Generate.\n",
    "        x = self.create_new_x(pick_num, draft_num)\n",
    "        y = self.create_new_y(pick_num, draft_num)\n",
    "        return x, y\n",
    "    \n",
    "    def create_new_x(self, pick_num, draft_num):\n",
    "        \"\"\"Generate x, input, as a row vector.\n",
    "        0:n     : collection vector\n",
    "                  x[i]=n -> collection has n copies of card i\n",
    "        n:2n    : pack vector\n",
    "                  0 -> card not in pack\n",
    "                  1 -> card in pack\n",
    "        Efficiency optimization possible. Iterative adds to numpy array.\n",
    "        \"\"\"\n",
    "        #Initialize collection / cards in pack vector.\n",
    "        x = np.zeros([self.cards_in_set * 2], dtype = \"int16\")\n",
    "        \n",
    "        #Fill in collection vector excluding current pick (first half).\n",
    "        for n in self.drafts_tensor[draft_num, :pick_num, 0]:\n",
    "            x[n] += 1\n",
    "            \n",
    "        #Fill in pack vector.\n",
    "        cards_in_pack =  self.pack_size - pick_num%self.pack_size #Cards in current pack.\n",
    "        for n in self.drafts_tensor[draft_num, pick_num, :cards_in_pack]:\n",
    "            x[n + self.cards_in_set] = 1\n",
    "            \n",
    "        #Convert to Torch tensor.\n",
    "        x = torch.Tensor(x)\n",
    "        return x\n",
    "    \n",
    "    def create_new_y(self, pick_num, draft_num, not_in_pack=0.5):\n",
    "        \"\"\"Generate y, a target pick row vector.\n",
    "        Picked card is assigned a value of 1.\n",
    "        Other cards are assigned a value of 0.\n",
    "        \"\"\"\n",
    "        #Initialize target vector.\n",
    "        #y = np.array([0] * self.cards_in_set)\n",
    "        y = np.zeros([self.cards_in_set], dtype = \"int16\")\n",
    "            \n",
    "        #Add picked card.\n",
    "        y[self.drafts_tensor[draft_num, pick_num, 0]] = 1\n",
    "        y = torch.Tensor(y)\n",
    "        return y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.drafts_tensor)\n",
    "\n",
    "def load_dataset(rating_path1, rating_path2, drafts_path):\n",
    "    \"\"\"Create drafts tensor from drafts and set files.\"\"\"\n",
    "    # Load the set. inputs\n",
    "    cur_set = ds.create_set(rating_path1, rating_path2)\n",
    "    raw_drafts = ds.load_drafts(drafts_path)\n",
    "    \n",
    "    # Fix commas. \n",
    "    cur_set, raw_drafts = ds.fix_commas(cur_set, raw_drafts)\n",
    "    \n",
    "    # Process drafts. \n",
    "    drafts = ds.process_drafts(raw_drafts)\n",
    "    \n",
    "    # Drop empty elements at end, if present. \n",
    "    while len(drafts[-1]) == 0:\n",
    "        drafts = drafts[:-1]\n",
    "    \n",
    "    # Create a label encoder.\n",
    "    le = create_le(cur_set[\"Name\"].values)\n",
    "    \n",
    "    # Create drafts tensor. \n",
    "    drafts_tensor = drafts_to_tensor(drafts, le)\n",
    "    \n",
    "    # Create a dataset.\n",
    "    cur_dataset = DraftDataset(drafts_tensor, le)\n",
    "    \n",
    "    # Get the tensor\n",
    "    return cur_dataset, drafts_tensor, cur_set, le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing draft: 0.\n",
      "Processing draft: 0.\n"
     ]
    }
   ],
   "source": [
    "# Define rating file paths. \n",
    "rating_path1 = \"data/m19_rating.tsv\"\n",
    "rating_path2 = \"data/m19_land_rating.tsv\"\n",
    "\n",
    "# Load data. \n",
    "train_data, train_tensor, m19_set, le = load_dataset(rating_path1, rating_path2, \"data/subset20000/train_small.csv\")\n",
    "val_data, val_tensor, m19_set, le = load_dataset(rating_path1, rating_path2, \"data/subset20000/val_small.csv\")\n",
    "#test_data, test_tensor, m19_set, le = load_dataset(rating_path1, rating_path2, \"data/subset20000/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DraftNet(\n",
      "  (linear1): Linear(in_features=285, out_features=285, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (dropout1): Dropout(p=0.1)\n",
      "  (linear2): Linear(in_features=285, out_features=285, bias=True)\n",
      "  (relu2): ReLU()\n",
      "  (linear3): Linear(in_features=285, out_features=285, bias=True)\n",
      "  (relu3): ReLU()\n",
      "  (linear4): Linear(in_features=285, out_features=285, bias=True)\n",
      "  (relu4): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Implement NN.\n",
    "class DraftNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, ss):\n",
    "        \"\"\"Placeholder NN. Currently does nothing.\n",
    "        \n",
    "        param ss: number of cards in set\n",
    "        \"\"\"\n",
    "        super(DraftNet, self).__init__()\n",
    "        \n",
    "        self.ss = ss\n",
    "\n",
    "        size_in = self.ss\n",
    "        size1 = self.ss\n",
    "        size2 = self.ss\n",
    "        size3 = self.ss\n",
    "        size4 = self.ss\n",
    "        \n",
    "        #Placeholder. \n",
    "        #x -> (4, 285, 2)\n",
    "        #y -> (4, 285, 1)inputs\n",
    "        self.linear1 = torch.nn.Linear(size_in, size1)\n",
    "        self.relu1 = torch.nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.1)\n",
    "        \n",
    "        self.linear2 = torch.nn.Linear(size1, size2)\n",
    "        self.relu2 = torch.nn.ReLU()\n",
    "        #self.dropout2 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.linear3 = torch.nn.Linear(size2, size3)\n",
    "        self.relu3 = torch.nn.ReLU()\n",
    "        #self.dropout3 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.linear4 = torch.nn.Linear(size3, size4)\n",
    "        self.relu4 = torch.nn.ReLU()\n",
    "        \n",
    "        #self.sm = torch.nn.Softmax()\n",
    "                \n",
    "    def forward(self, x):\n",
    "        \n",
    "        collection = x[:, :self.ss]\n",
    "        pack = x[:, self.ss:]\n",
    "        \n",
    "        y = self.linear1(collection)\n",
    "        y = self.relu1(y)\n",
    "        y = self.dropout1(y)\n",
    "        \n",
    "        y = self.linear2(y)\n",
    "        y = self.relu2(y)\n",
    "        \n",
    "        y = self.linear3(y)\n",
    "        y = self.relu3(y)\n",
    "\n",
    "        y = self.linear4(y)\n",
    "        y = self.relu4(y)\n",
    "        \n",
    "        y = y * pack # Enforce cards in pack only.\n",
    "       \n",
    "        #y = self.sm(y, dim=1)\n",
    "        \n",
    "        #y = F.log_softmax(y, dim=1)\n",
    "        \n",
    "        return y\n",
    "\n",
    "#Create NN.\n",
    "net = DraftNet(len(m19_set)).cuda()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net(net, dataloader, num_epoch, criterion, optimizer):\n",
    "    \"\"\"Train the network.\"\"\"\n",
    "    \n",
    "    net.train()\n",
    "    \n",
    "    for epoch in range(num_epoch):\n",
    "        \n",
    "        #Loop over x,y for each dataset.\n",
    "        running_loss = 0\n",
    "        for i, data in enumerate(dataloader):\n",
    "        \n",
    "            #Get the inputs. Keeps batch size.\n",
    "            x, y = data\n",
    "            \n",
    "            # cuda() is needed for GPU mode. Not sure why.\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "            \n",
    "            # Zero parameter gradients between batches.\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            #Perform training.\n",
    "            y_pred = net(x)\n",
    "            loss = criterion(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            #Print loss data.\n",
    "            running_loss += loss.item()\n",
    "            step = 1\n",
    "            if i % len(dataloader) == len(dataloader)-1 and (epoch + 1) % step == 0:\n",
    "                print('Epoch %d, Average Loss: %.6f' % (epoch+1, running_loss/len(dataloader)))\n",
    "                running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Average Loss: 0.003426\n",
      "Epoch 2, Average Loss: 0.003423\n",
      "Epoch 3, Average Loss: 0.003421\n",
      "Epoch 4, Average Loss: 0.003418\n",
      "Epoch 5, Average Loss: 0.003417\n",
      "Epoch 6, Average Loss: 0.003415\n",
      "Epoch 7, Average Loss: 0.003412\n",
      "Epoch 8, Average Loss: 0.003410\n",
      "Epoch 9, Average Loss: 0.003409\n",
      "Epoch 10, Average Loss: 0.003405\n",
      "Epoch 11, Average Loss: 0.003403\n",
      "Epoch 12, Average Loss: 0.003402\n",
      "Epoch 13, Average Loss: 0.003400\n",
      "Epoch 14, Average Loss: 0.003398\n",
      "Epoch 15, Average Loss: 0.003395\n",
      "Epoch 16, Average Loss: 0.003392\n",
      "Epoch 17, Average Loss: 0.003387\n",
      "Epoch 18, Average Loss: 0.003384\n",
      "Epoch 19, Average Loss: 0.003384\n",
      "Epoch 20, Average Loss: 0.003380\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "# Define training parameters. #\n",
    "###############################\n",
    "net = net\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=10, shuffle=True)\n",
    "num_epoch = 20\n",
    "train_criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.2, momentum=0.2)\n",
    "\n",
    "#################\n",
    "# Train network #\n",
    "#################\n",
    "train_net(net, trainloader, num_epoch, train_criterion, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_net(net, dataloader, criterion):\n",
    "    net.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(dataloader):\n",
    "        \n",
    "            #Get the inputs. Keeps batch size.\n",
    "            x, y = data\n",
    "            \n",
    "            # cuda() is needed for GPU mode. Not sure why.\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "            \n",
    "            # Compute val loss.\n",
    "            y_pred = net(x)\n",
    "            #val_loss += criterion(y_pred, y, reduction='sum').item() # sum up batch loss\n",
    "            val_loss += val_criterion(y_pred, y)\n",
    "            \n",
    "            # Get prediction. \n",
    "            pred = y_pred.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(y.view_as(pred)).sum().item()\n",
    "            \n",
    "    test_loss /= len(dataloader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(dataloader.dataset),\n",
    "        100. * correct / len(dataloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[10, 1]' is invalid for input of size 2850",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0513fc35ad27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Train network #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mval_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_criterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-8971088c6c68>\u001b[0m in \u001b[0;36mval_net\u001b[0;34m(net, dataloader, criterion)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;31m# Get prediction.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mtest_loss\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[10, 1]' is invalid for input of size 2850"
     ]
    }
   ],
   "source": [
    "#################################\n",
    "# Define validation parameters. #\n",
    "#################################\n",
    "net = net\n",
    "valloader = torch.utils.data.DataLoader(val_data, batch_size=10, shuffle=True)\n",
    "val_criterion = nn.MSELoss()\n",
    "\n",
    "#################\n",
    "# Train network #\n",
    "#################\n",
    "val_net(net, valloader, val_criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Do:\n",
    "# 1. Debug loss function. \n",
    "# 2. Run validation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
